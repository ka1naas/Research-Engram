'''
åŠŸèƒ½bå…ˆå¸®ç”¨æˆ·ç”Ÿæˆæˆ–æ”¹è¿›ideaï¼ˆæ­¤æ—¶ç”¨æˆ·
æ²¡æœ‰ideaæˆ–è€…ç”¨æˆ·å…¶å®æœ¬èº«å·²ç»çŸ¥é“ideaæœ‰é—®é¢˜ï¼Œæ‰ä¼šé€‰æ‹©è®©aiå¸®å¿™è¿­ä»£ï¼‰
è€ŒåŠŸèƒ½cï¼Œæ˜¯åœ¨ç”¨æˆ·å·²ç»æœ‰ideaçš„æƒ…å†µä¸‹ï¼Œéœ€è¦ä¸€ç‚¹æ‰¹è¯„æ—¶æ‰é‡‡ç”¨çš„
'''
import os
from sqlalchemy.orm import Session
from pypdf import PdfReader
from fastapi import UploadFile
import schemas, crud
from vector_memory import VectorMemory
import datetime
import openai
from dotenv import load_dotenv
import models
import utils
import json

# è¯»å– .env
load_dotenv()

# åˆå§‹åŒ– DeepSeek
client = openai.OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"), # ä»ç³»ç»Ÿç¯å¢ƒå˜é‡é‡Œæ‹¿é’¥åŒ™ï¼Œè€Œä¸æ˜¯å†™æ­»åœ¨ä»£ç é‡Œ
    base_url="https://api.deepseek.com"
)

# åˆå§‹åŒ–å‘é‡è®°å¿†åº“ï¼ˆå•ä¾‹æ¨¡å¼ï¼šæ•´ä¸ªç³»ç»Ÿåªç”¨è¿™ä¸€ä¸ªå®ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾ vector_memory.py åœ¨åŒä¸€ç›®å½•ä¸‹
memory_core = VectorMemory()

# ================= åŠŸèƒ½Aï¼šæ¥æ”¶pdfï¼Œllmæå–æ‘˜è¦ï¼Œå­˜å…¥å‘é‡åº“ =================
async def process_paper_upload(
    user_id: int, 
    idea_id: int, 
    file: UploadFile, 
    db: Session
):
    """
    ä¸šåŠ¡é€»è¾‘ï¼šä¸Šä¼  PDF -> è§£ææ–‡æœ¬ -> å­˜ SQL -> å­˜å‘é‡åº“
    """
    
    # 1. è¯»å– PDF å†…å®¹ (I/O æ“ä½œ)
    # UploadFile æ˜¯ FastAPI çš„ç‰¹æœ‰ç±»å‹ï¼Œç±»ä¼¼äºä¸€ä¸ªæ‰“å¼€çš„æ–‡ä»¶å¥æŸ„
    content = await file.read() 
    
    # ä¸ºäº†ç”¨ pypdf è¯»å–ï¼Œæˆ‘ä»¬éœ€è¦æŠŠäºŒè¿›åˆ¶å­˜æˆä¸´æ—¶æ–‡ä»¶ï¼Œæˆ–è€…ç”¨ BytesIO
    # è¿™é‡Œä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œæˆ‘ä»¬å‡è®¾æ˜¯ä¸€ä¸ªæ ‡å‡†çš„æ–‡æœ¬æå–æµç¨‹
    import io
    pdf_file = io.BytesIO(content) # æŠŠäºŒè¿›åˆ¶æµå˜æˆåƒæ–‡ä»¶ä¸€æ ·å¯è¯»çš„å¯¹è±¡
    reader = PdfReader(pdf_file)
    
    full_text = ""
    for i,page in enumerate(reader.pages):
        if i >10:break
        text = page.extract_text()
        if text:
            full_text += page.extract_text() + "\n"
    
    # 2. ä½¿ç”¨deepseekç”Ÿæˆæ‘˜è¦
    print("ä½¿ç”¨deepseekç”Ÿæˆæ‘˜è¦ä¸­...")
    structure_prompt = """
    ä½ æ˜¯ä¸€ä¸ªç§‘ç ”è®ºæ–‡åˆ†æå¸ˆã€‚è¯·åˆ†æè¿™ç¯‡è®ºæ–‡ï¼Œè¾“å‡ºçº¯ JSON å¯¹è±¡ï¼š
    {
        "summary": "300å­—ä¸­æ–‡æ‘˜è¦",
        "claims": ["æ ¸å¿ƒè´¡çŒ®1", "æ ¸å¿ƒè´¡çŒ®2"],
        "critiques": ["æŒ‡å‡ºçš„ç°æœ‰æ–¹æ³•ç¼ºé™·", "æœ¬è®ºæ–‡æ–¹æ³•çš„å±€é™æ€§", "åç›´è§‰çš„å®éªŒç»“æœ"]
    }
    """
    try:
        response = client.chat.completions.create(
            model = 'deepseek-chat',
            messages=[
                {'role':'system','content': structure_prompt},
                {'role':'user','content':full_text[:2000]}# å‘é€å‰2000å­—ç¬¦ï¼Œé˜²æ­¢è¶…é•¿
            ],
            stream=False
        )
        # è§£æ JSON (å¢åŠ å®¹é”™)
        import json
        content_str = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        analysis = json.loads(content_str)
        
        abstract = analysis.get("summary", "æ‘˜è¦ç”Ÿæˆå¤±è´¥")
        critiques = analysis.get("critiques", [])
        if abstract == "æ‘˜è¦ç”Ÿæˆå¤±è´¥":
            print("deepseekç”Ÿæˆæ‘˜è¦å¤±è´¥...")
        else:
            print("deepseekæˆåŠŸç”Ÿæˆæ‘˜è¦ï¼")

    except Exception as e:
        print("deepseekæ€»ç»“å¤±è´¥ï¼Œé‡‡ç”¨å…¶ä»–æ–¹æ¡ˆï¼š{e}")
        #æå–å‰500å­—ä½œä¸ºæ‘˜è¦
        abstract = full_text[:500] + "..."

    title = file.filename # æš‚æ—¶ç”¨æ–‡ä»¶åå½“æ ‡é¢˜

    # 3. è°ƒç”¨ CRUD å±‚ï¼šå­˜å…¥ SQL æ•°æ®åº“
    # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†ä¿è¯æ— è®ºå‘é‡åº“æŒ‚æ²¡æŒ‚ï¼Œæˆ‘ä»¬çš„åŸºç¡€æ•°æ®éƒ½åœ¨
    paper_schema = schemas.PaperCreate(title=title, abstract=abstract, idea_id=idea_id)
    db_paper = crud.create_paper_record(db=db, paper=paper_schema, user_id=user_id)

    # 4. è°ƒç”¨ VectorMemoryï¼šå­˜å…¥å‘é‡æ•°æ®åº“
    # æˆ‘ä»¬æŠŠ paper_id å­˜è¿›å»ï¼Œè¿™æ ·ä»¥åæ£€ç´¢åˆ°å‘é‡ï¼Œèƒ½åå‘æŸ¥åˆ° SQL é‡Œçš„å®Œæ•´ä¿¡æ¯
    # ä¸ºäº† **å¯¹æŠ—æ€§æ£€ç´¢** æˆ‘ä»¬å­˜å…¥æ‘˜è¦çš„åŒæ—¶ï¼Œå­˜å…¥æ‰¹é©³
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    metadata_true = {
        "role": "paper_summary",
        "user_id": user_id,
        "idea_id": idea_id,
        "paper_db_id": db_paper.id, # å…³é”®ï¼šå»ºç«‹ SQL å’Œ Vector çš„è”ç³»
        "timestamp": current_time 
    }

    metadata_false={
                "role": "paper_critique", # ğŸ‘ˆ å…³é”®æ ‡ç­¾
                "user_id": user_id,
                "idea_id": idea_id,
                "paper_db_id": db_paper.id,
                "timestamp": current_time 
    }
    
    # æ„é€ å­˜å…¥å‘é‡åº“çš„æ–‡æœ¬
    # ---- æ­£å‘å­˜å‚¨ æŠŠæ‘˜è¦å’Œé¢˜ç›®å­˜åœ¨ä¸€èµ· ----
    save_text = f'è®ºæ–‡æ ‡é¢˜ï¼š{title}\nAIæ‘˜è¦:{abstract}\n'
    memory_core.add_memory(
        text=save_text, 
        metadata=metadata_true,
        mem_id=f"paper_{db_paper.id}"
    )

    # ---- åå‘å­˜å‚¨ å­˜å…¥æ‰¹é©³ ----
    if critiques:
        critique_text = f"è®ºæ–‡æ ‡é¢˜ï¼š{title}\nå±€é™ä¸åæ€ï¼š{'; '.join(critiques)}"
        memory_core.add_memory(
            text=critique_text,
            metadata=metadata_false
        )


    print("è®ºæ–‡æˆå­˜å…¥ï¼")

    return db_paper

# ================= åŠŸèƒ½Bï¼šæ¥æ”¶idea/Noneï¼Œllmæå–æ‘˜è¦æ€»ç»“new idea/ideaå­˜å…¥å‘é‡åº“ =================
async def chat_with_deepseek(
    db: Session, 
    request: schemas.ChatRequest
):
    # 1. è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
    user = db.query(models.User).filter(models.User.id == request.user_id).first()
    if not user:
        raise Exception('User not found')
    
    # è·å–ç”¨æˆ·ç”»åƒ
    user_persona = user.persona if user.persona else "è¯¥ç”¨æˆ·æš‚æ— ç”»åƒ"

    # 2. åˆ¤å®šåœºæ™¯ï¼ˆæœ‰æ— ç”¨æˆ·ideaï¼‰å¹¶ç»„è£…å¯¹åº”çš„prompt
    #åˆå§‹åŒ–
    context_info = "" # ç”¨æˆ·prompt
    system_instruction = "" # ç³»ç»Ÿprompt

    # è®°å¿†æ£€ç´¢
    #å¦‚æœæœ‰ideaï¼Œæœideaç›¸å…³ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå…¨æœç´¢
    query_for_search = request.query
    search_results = memory_core.search_memory(query_for_search)
    memory_context = '\n'.join([f"- {r['content']}" for r in search_results])

    # -- åˆ†å‰²åœºæ™¯ --
    # å¦‚æœç›®å‰å¯¹è¯ç”¨æˆ·å·²ç»ç»‘å®šäº†idea
    if request.idea_id:
        idea = db.query(models.Idea).filter(models.Idea.id == request.idea_id).first()
        context_info += f"\nã€å½“å‰è®¨è®ºçš„ Ideaã€‘: {idea.title}\n{idea.description}\n"

        if request.paper_id:
            # åœºæ™¯ 1: æœ‰Ideaä¹Ÿæœ‰Paper
            paper = db.query(models.Paper).filter(models.Paper.id == request.paper_id)
            context_info += f"\nã€å½“å‰å‚è€ƒçš„ Paperã€‘: {paper.title}\næ‘˜è¦: {paper.abstract}\n"
            system_instruction = """
                ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç§‘ç ”åˆä½œè€…ã€‚
                ä½ çš„ä»»åŠ¡æ˜¯ï¼šåŸºäºç”¨æˆ·æä¾›çš„ Paperï¼Œæ‰¹åˆ¤æ€§åœ°å®¡è§†ç”¨æˆ·çš„ Ideaã€‚
                è¯·æŒ‡å‡º Idea ä¸ Paper çš„è”ç³»ã€æ½œåœ¨çš„çŸ›ç›¾ç‚¹ï¼Œæˆ– Paper å¦‚ä½•èƒ½æ”¯æ’‘è¿™ä¸ª Ideaã€‚
                """
        
        else:
            # åœºæ™¯ 2ï¼šåªæœ‰ideaæ²¡æœ‰Paper
            system_instruction = """
            ä½ æ˜¯ä¸€ä¸ªç§‘ç ”å¯¼å¸ˆã€‚ç”¨æˆ·æ­£åœ¨æ„æ€ä¸€ä¸ª Ideaï¼Œä½†ä»–å¯èƒ½è¿˜æ²¡æƒ³æ¸…æ¥šã€‚
            ä½ çš„ä»»åŠ¡æ˜¯ï¼šå¸®åŠ©ç”¨æˆ·å®Œå–„è¿™ä¸ª Ideaï¼Œé€šè¿‡æé—®æˆ–å»ºè®®ï¼Œè®© Idea å˜å¾—æ›´å…·ä½“ã€æ›´æœ‰é€»è¾‘ã€‚
            å¦‚æœç”¨æˆ·è¦æ±‚ï¼Œè¯·å¸®åŠ©ä¿®æ”¹ Idea çš„æè¿°ã€‚
            """
    
    #å¦‚æœç”¨æˆ·æ²¡æœ‰ç»‘å®šIdea
    elif request.paper_id:
        # åœºæ™¯ 3ï¼š åªæœ‰Paperæ²¡æœ‰Idea
        paper = db.query(models.Paper).filter(models.Paper.id == request.paper_id)
        context_info += f"\nã€å½“å‰å‚è€ƒçš„ Paperã€‘: {paper.title}\næ‘˜è¦: {paper.abstract}\n"
        system_instruction = """
            ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç§‘ç ”åˆä½œè€…ã€‚
            ä½ çš„ä»»åŠ¡æ˜¯ï¼šåŸºäºç”¨æˆ·æä¾›çš„ Paperï¼Œæ€»ç»“å‡ºä¸ç”¨æˆ·ç ”ç©¶ç›¸å…³çš„ Ideaã€‚
            å¹¶è¯·æŒ‡å‡º Idea ä¸ Paper çš„è”ç³»ï¼Œæˆ– Paper å¦‚ä½•èƒ½æ”¯æ’‘è¿™ä¸ª Ideaã€‚
            """
        
    else:
        # åœºæ™¯ 4ï¼š æ²¡æœ‰ideaä¹Ÿæ²¡æœ‰paper
        system_instruction = """
        ä½ æ˜¯ä¸€ä¸ªç§‘ç ”çµæ„ŸåŠ©æ‰‹ã€‚ç”¨æˆ·ç›®å‰æ²¡æœ‰æŒ‡å®šå…·ä½“çš„ Ideaã€‚
        ä½ çš„ä»»åŠ¡æ˜¯ï¼šé€šè¿‡å¯¹è¯å¼•å¯¼ç”¨æˆ·æŒ–æ˜ä»–ä»¬çš„æƒ³æ³•ã€‚
        ã€é‡è¦ã€‘ï¼šå¦‚æœä½ æ•é”åœ°å‘ç°ç”¨æˆ·æ­£åœ¨è¡¨è¾¾ä¸€ä¸ªæˆå‹çš„ç§‘ç ”æƒ³æ³•ï¼Œè¯·åœ¨å›ç­”çš„æœ€åï¼Œ
        ç”¨ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚ <SUGGEST_IDEA>å†…å®¹</SUGGEST_IDEA>ï¼‰æ€»ç»“å‡ºè¿™ä¸ª Ideaï¼Œä»¥ä¾¿ç³»ç»Ÿæå–ã€‚
        """
    
    # 3. æœ€ç»ˆæ‹¼æ¥prompt
    final_prompt = f"""
    {system_instruction}
    
    ã€ç”¨æˆ·ç”»åƒã€‘:
    {user_persona}
    
    ã€ç›¸å…³å†å²è®°å¿†ã€‘:
    {memory_context}
    
    ã€å½“å‰ä¸Šä¸‹æ–‡ã€‘:
    {context_info}
    """

    # 4. è°ƒç”¨ DeepSeek (è¿™æ˜¯ä¹‹å‰ç¼ºå¤±çš„éƒ¨åˆ†)
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": final_prompt},
                {"role": "user", "content": request.query}
            ],
            stream=False
        )
        ai_content = response.choices[0].message.content

        # 5. è§£ææ˜¯å¦æœ‰æ–° Idea å»ºè®®
        suggested_idea = None
        # ä½¿ç”¨æ­£åˆ™æå– <SUGGEST_IDEA> æ ‡ç­¾é‡Œçš„å†…å®¹
        match = re.search(r"<SUGGEST_IDEA>(.*?)</SUGGEST_IDEA>", ai_content, re.DOTALL)
        if match:
            suggested_idea = match.group(1).strip()
            # ç§»é™¤æ ‡ç­¾ï¼Œä¿æŒå›å¤æ•´æ´
            ai_content = ai_content.replace(match.group(0), "\n\n(ç³»ç»Ÿæç¤ºï¼šå·²ä¸ºæ‚¨æ•æ‰åˆ°ä¸€ä¸ªæ–°çµæ„Ÿï¼Œè¯·æŸ¥çœ‹å»ºè®®å¡ç‰‡)")

        # 6. å¤„ç†æ˜¾å¼çŸ¥è¯†å­˜å‚¨ (å¦‚æœç”¨æˆ·å‹¾é€‰äº† "ä¿å­˜ä¸ºçŸ¥è¯†")
        if request.save_as_knowledge:
            memory_core.add_memory(
                text=f"ã€ç”¨æˆ·ç²¾é€‰çŸ¥è¯†ã€‘é—®:{request.query}\nç­”:{ai_content}",
                metadata={
                    "user_id": request.user_id,
                    "role": "explicit_knowledge",
                    "heat": 999, # æ ‡è®°ä¸ºé«˜çƒ­åº¦
                    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
            )

        # 7. è¿”å›æ ‡å‡†å“åº”å¯¹è±¡ (Schemas éœ€è¦å®šä¹‰ ChatResponse)
        return schemas.ChatResponse(
            response_text=ai_content,
            suggested_idea=suggested_idea,
            used_references=[r['content'][:20] for r in search_results]
        )

    except Exception as e:
        print(f"Chat Error: {e}")
        # è¿”å›ä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„å“åº”
        return schemas.ChatResponse(response_text="æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚")

# ================= åŠŸèƒ½Cï¼šè¿›è¡Œå¯¹æŠ—æ€§æ£€ç´¢ =================  
async def critical_agent_chat(
    db: Session,
    user_id: int,
    query: str,
    idea_id: int = None
):
    """
    æ­£å‘æ£€ç´¢ + åå‘æ”»å‡» + é€»è¾‘æ‰“åˆ†ã€‚
    """
    
    # 1. åŸºç¡€ä¸Šä¸‹æ–‡æ£€ç´¢ (æ­£å‘)
    support_results = memory_core.search_memory(query, n_results=3)
    support_text = "\n".join([f"- {r['content']}" for r in support_results])

    # 2. å¯¹æŠ—æ€§æ£€ç´¢ (åå‘)
    print("æ­£åœ¨è¿›è¡Œæ‰¹åˆ¤æ€§æ€è€ƒ...")
    # ç”Ÿæˆåå‘å…³é”®è¯
    bad_keywords = utils.generate_adversarial_keywords(query)
    
    critique_evidences = []
    # å»å‘é‡åº“é‡Œä¸“é—¨æœ role='paper_critique' çš„æ•°æ®
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ vector_memory.search_memory ä»¥åå¯ä»¥æ”¯æŒ filter å‚æ•°
    # ç›®å‰å…ˆç®€å•æœå…¨æ–‡
    for kw in bad_keywords:
        res = memory_core.search_memory(kw, n_results=2)
        critique_evidences.extend(res)

    # 3. é€»è¾‘å†²çªé‡åŒ– (The Metric)
    high_conflict_points = []
    for evi in critique_evidences:
        # è°ƒç”¨ utils é‡Œçš„é‡åŒ–å™¨
        assessment = utils.calculate_conflict_score(query, evi['content'])
        
        if assessment['score'] >= 6: # åªæœ‰å†²çªåˆ†å¤§äº6çš„æ‰å€¼å¾—æŠ¥å‘Š
            high_conflict_points.append({
                "content": evi['content'],
                "score": assessment['score'],
                "reason": assessment['reason']
            })

    # 4. ç»„è£…æœ€ç»ˆ Agent Prompt
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸ä»…æä¾›å¸®åŠ©ï¼Œæ›´æä¾›â€œæ·±åº¦æ´å¯Ÿâ€çš„ç§‘ç ”ä¼™ä¼´ã€‚
    ç”¨æˆ·æ­£åœ¨æ€è€ƒï¼š"{query}"
    
    ã€å·²æœ‰æ”¯æŒè¯æ®ã€‘:
    {support_text}
    
    ã€âš ï¸ æ½œåœ¨çš„é€»è¾‘é£é™© (åŸºäºç°æœ‰è®ºæ–‡çš„åé©³)ã€‘:
    {json.dumps(high_conflict_points, ensure_ascii=False)}
    
    è¯·å›å¤ç”¨æˆ·ï¼š
    1. é¦–å…ˆè‚¯å®š Idea çš„ä»·å€¼ï¼ˆå¦‚æœæœ‰æ”¯æŒè¯æ®ï¼‰ã€‚
    2. **æ ¸å¿ƒä»»åŠ¡**ï¼šå¦‚æœå­˜åœ¨é«˜åˆ†å†²çªï¼ˆScore > 6ï¼‰ï¼Œå¿…é¡»ä¸¥è‚ƒæŒ‡å‡ºè¿™ä¸ª Idea çš„æ½œåœ¨ç¼ºé™·ã€‚ä¸è¦ä¸€å‘³èµåŒã€‚
    3. ç»¼åˆå»ºè®®ä¸‹ä¸€æ­¥è¯¥æ€ä¹ˆåšã€‚
    """

    # 5. ç”Ÿæˆæœ€ç»ˆå›å¤
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "system", "content": system_prompt}],
        stream=False
    )
    
    return response.choices[0].message.content




