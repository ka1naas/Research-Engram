'''
æ­¤ä»£ç ç”¨äºç”Ÿæˆç”¨æˆ·ç”»åƒ,æå–å¯¹è¯å†…å®¹ï¼Œä½œä¸ºçŸ¥è¯†
'''
import time
import json
import os
import datetime
from sqlalchemy.orm import Session
from database import SessionLocal
import models
from vector_memory import VectorMemory
import openai
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
client = openai.OpenAI(
    api_key=os.getenv('DEEPSEEK_API_KEY'),
    base_url="https://api.deepseek.com"
)

# åˆå§‹åŒ–å‘é‡åº“ (ä½œä¸ºå†™å…¥ç›®æ ‡)
memory_core = VectorMemory()

def get_messages_since_last_sleep(db: Session, user: models.User):
    """
    ä» SQL ä¸­æå–è‡ªä¸Šæ¬¡ç¡çœ ä»¥æ¥çš„æ‰€æœ‰å¯¹è¯
    """
    # æŸ¥æ‰¾æ‰€æœ‰ created_at > last_sleep_time çš„æ¶ˆæ¯
    new_msgs = db.query(models.Message).filter(
        models.Message.user_id == user.id,
        models.Message.created_at > user.last_sleep_time
    ).order_by(models.Message.created_at.asc()).all()
    
    return new_msgs

def generate_implicit_knowledge(user_id: int, chat_history_text: str):
    """
    ã€ä»»åŠ¡ Bã€‘: éšå¼çŸ¥è¯†å›ºåŒ–
    è®© AI åƒçœ‹è¯¾å ‚ç¬”è®°ä¸€æ ·ï¼Œä»å¯¹è¯ä¸­æ€»ç»“å‡ºçŸ¥è¯†ç‚¹
    """
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªç§‘ç ”çŸ¥è¯†æ•´ç†å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯é˜…è¯»ç”¨æˆ·çš„èŠå¤©è®°å½•ï¼Œæå–å‡º**é•¿æœŸæœ‰ä»·å€¼çš„ç§‘ç ”çŸ¥è¯†**ã€‚
    
    è¯·æå–ä»¥ä¸‹ç±»å‹çš„å†…å®¹ï¼š
    1. ç”¨æˆ·ç¡®è®¤è¿‡çš„ Idea ç»†èŠ‚æˆ–ä¿®æ”¹æ–¹å‘ã€‚
    2. æ˜ç¡®çš„ç§‘ç ”ç»“è®ºæˆ–å®éªŒçº¦æŸæ¡ä»¶ã€‚
    3. æœ‰ä»·å€¼çš„å‚è€ƒæ–‡çŒ®æˆ–ç†è®ºä¾æ®ã€‚
    
    âŒ å¿½ç•¥ä»¥ä¸‹å†…å®¹ï¼š
    - é—²èŠ ("ä½ å¥½", "è°¢è°¢")
    - è¿‡ç¨‹æ€§çš„çº ç»“ ("æˆ‘å†æƒ³æƒ³")
    - ç®€å•çš„æŒ‡ä»¤ ("å¸®æˆ‘æ”¹ä¸€ä¸‹")

    å¦‚æœæå–åˆ°äº†çŸ¥è¯†ï¼Œè¯·è¾“å‡º JSON åˆ—è¡¨ï¼Œæ ¼å¼ï¼š
    [{"content": "çŸ¥è¯†ç‚¹å†…å®¹...", "tags": ["Ideaè¿­ä»£", "CV"]}]
    
    å¦‚æœæ²¡æœ‰æå–åˆ°ä»»ä½•æœ‰ä»·å€¼çš„çŸ¥è¯†ï¼Œè¯·ç›´æ¥è¾“å‡ºç©ºåˆ—è¡¨ []ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ã€ä»Šæ—¥å¯¹è¯è®°å½•ã€‘:\n{chat_history_text}"}
            ],
            stream=False
        )
        content = response.choices[0].message.content
        # æ¸…æ´—ä¸€ä¸‹ markdown
        content = content.replace("```json", "").replace("```", "").strip()
        knowledge_list = json.loads(content)
        return knowledge_list
    except Exception as e:
        print(f"  [çŸ¥è¯†æå–å¤±è´¥] {e}")
        return []

def update_user_persona(current_persona: str, chat_history_text: str):
    """
    ã€ä»»åŠ¡ Aã€‘: æ›´æ–°ç”¨æˆ·ç”»åƒ
    """
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·ç”»åƒä¾§å†™å¸ˆã€‚è¯·æ ¹æ®ä»Šæ—¥çš„å¯¹è¯æ›´æ–°ç”¨æˆ·çš„ã€ç§‘ç ”ç”»åƒã€‘ã€‚
    
    ç­–ç•¥ï¼š
    1. **éªŒè¯**ï¼šå¼ºåŒ–å·²éªŒè¯çš„ç‰¹å¾ã€‚
    2. **ä¿®æ­£**ï¼šå¦‚æœå‘ç°ç”¨æˆ·æ”¹å˜äº†ç ”ç©¶æ–¹å‘ï¼ˆå¦‚ä» NLP è½¬åš CVï¼‰ï¼Œè¯·ä¿®æ­£ç”»åƒã€‚
    3. **æ–°å¢**ï¼šå‘ç°æ–°çš„åå¥½æˆ–ä¹ æƒ¯ã€‚
    
    è¯·ç›´æ¥è¾“å‡ºæ›´æ–°åçš„ JSON åˆ—è¡¨ï¼ˆä¸è¦åºŸè¯ï¼‰ï¼Œä¾‹å¦‚ï¼š["ç ”ç©¶æ–¹å‘: Transformer", "åå¥½: PyTorch"]
    """
    
    user_prompt = f"""
    ã€æ—§ç”»åƒã€‘: {current_persona}
    ã€ä»Šæ—¥å¯¹è¯ã€‘: {chat_history_text}
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=False
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        # ç®€å•éªŒè¯ä¸€ä¸‹æ˜¯ä¸æ˜¯ JSON
        json.loads(content) 
        return content
    except Exception as e:
        print(f"  [ç”»åƒæ›´æ–°å¤±è´¥] {e}")
        return current_persona # å¤±è´¥äº†å°±è¿”å›æ—§çš„ï¼Œåˆ«æ”¹åäº†

def process_one_user(db: Session, user: models.User):
    print(f"\nğŸ’¤ ç”¨æˆ· [{user.username}] è¿›å…¥ç¡çœ å¤„ç†...")

    # 1. è·å–æ–°è®°å¿† (ä» SQL è¯»å–)
    new_msgs = get_messages_since_last_sleep(db, user)
    
    if not new_msgs:
        print("  -> æ— æ–°å¯¹è¯ï¼Œè·³è¿‡ã€‚")
        # å³ä½¿æ²¡æœ‰æ–°å¯¹è¯ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©æ›´æ–°ä¸€ä¸‹æ—¶é—´ï¼Œæˆ–è€…ä¸åšæ“ä½œ
        return

    print(f"  -> å‘ç° {len(new_msgs)} æ¡æ–°å¯¹è¯ï¼Œå¼€å§‹å¤§è„‘æ•´ç†...")
    
    # æ‹¼è£…å¯¹è¯æ–‡æœ¬
    chat_text = ""
    for msg in new_msgs:
        chat_text += f"[{msg.role}]: {msg.content}\n"

    # 2. æ‰§è¡Œä»»åŠ¡ A: æ›´æ–°ç”»åƒ
    new_persona = update_user_persona(user.persona, chat_text)
    if new_persona != user.persona:
        print(f"  -> ç”»åƒå·²æ›´æ–°")
        user.persona = new_persona
    
    # 3. æ‰§è¡Œä»»åŠ¡ B: éšå¼çŸ¥è¯†æå– (The Magic)
    knowledge_list = generate_implicit_knowledge(user.id, chat_text)
    
    if knowledge_list:
        print(f"  -> æç‚¼å‡º {len(knowledge_list)} æ¡éšå¼çŸ¥è¯†ï¼Œæ­£åœ¨å›ºåŒ–...")
        for k in knowledge_list:
            text = k.get('content', '')
            if text:
                # å­˜å…¥å‘é‡åº“
                memory_core.add_memory(
                    text=f"ã€ç¡çœ æ•´ç†çŸ¥è¯†ã€‘{text}",
                    metadata={
                        "user_id": user.id,
                        "role": "implicit_knowledge", # å…³é”®æ ‡è®°ï¼šè¿™æ˜¯ç¡è§‰å¾—æ¥çš„
                        "source": "sleep_consolidation",
                        "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                )
    else:
        print("  -> ä»Šæ—¥å¯¹è¯ä¸»è¦æ˜¯é—²èŠï¼Œæœªæå–åˆ°æ·±åº¦çŸ¥è¯†ã€‚")

    # 4. æ ‡è®°ç¡çœ å®Œæˆ
    user.last_sleep_time = datetime.datetime.utcnow()
    db.commit()
    print(f"  -> [{user.username}] ç¡çœ ç»“æŸï¼Œç²¾åŠ›å·²æ¢å¤ã€‚")

def run_sleep_cycle():
    """
    ä¸»ç¨‹åº
    """
    print("=== ç ”ç©¶åŠ©æ‰‹åå°ç¡çœ ç³»ç»Ÿå¯åŠ¨ ===")
    db = SessionLocal()
    try:
        users = db.query(models.User).all()
        for user in users:
            process_one_user(db, user)
    finally:
        db.close()
        print("=== ç¡çœ å‘¨æœŸç»“æŸ ===")

if __name__ == "__main__":
    run_sleep_cycle()